{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6ace81d",
   "metadata": {},
   "source": [
    "# Cálculo matemático y gráficas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013d373",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cca9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625b7cc",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31eef343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_plot_style():\n",
    "    mpl.rcParams.update({\n",
    "        # Tamaño por defecto de las figuras (más ancha que alta)\n",
    "        \"figure.figsize\": (10, 4.5),  # ancho, alto en pulgadas\n",
    "\n",
    "        # Texto\n",
    "        \"font.size\": 11,\n",
    "        \"axes.titlesize\": 14, \"axes.titleweight\": \"bold\",\n",
    "        \"axes.labelsize\": 12, \"axes.labelweight\": \"bold\",\n",
    "\n",
    "        # Ejes y spines\n",
    "        \"axes.spines.right\": False, \"axes.spines.top\": False,\n",
    "        \"axes.linewidth\": 1.2,\n",
    "        \"xtick.major.width\": 1.0, \"ytick.major.width\": 1.0,\n",
    "\n",
    "        # Grid sutil\n",
    "        \"axes.grid\": True, \"grid.alpha\": 0.2, \"grid.linestyle\": \"-\",\n",
    "\n",
    "        # Leyenda\n",
    "        \"legend.frameon\": False,\n",
    "\n",
    "        # Colores agradables y consistentes\n",
    "        \"axes.prop_cycle\": plt.cycler(color=plt.cm.Set2.colors),\n",
    "\n",
    "        # Márgenes automáticos\n",
    "        \"figure.autolayout\": True\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20e005b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureDir(dir_file):\n",
    "    if not os.path.exists(dir_file):\n",
    "        os.makedirs(dir_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7b43390",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "LOGS_DIR = \"./logs\"\n",
    "GRAPH_DIR = \"../images/evidencia/graficas\"\n",
    "\n",
    "seq_files = {\n",
    "    \"impl1\": os.path.join(DATA_DIR, \"impl1\", \"sec.csv\"),\n",
    "    \"impl2\": os.path.join(DATA_DIR, \"impl2\", \"sec.csv\"),\n",
    "    \"impl3\": os.path.join(DATA_DIR, \"impl3\", \"sec.csv\")\n",
    "}\n",
    "\n",
    "par_files = {\n",
    "    \"impl1\": os.path.join(DATA_DIR, \"impl1\", \"par.csv\"),\n",
    "    \"impl2\": os.path.join(DATA_DIR, \"impl2\", \"par.csv\"),\n",
    "    \"impl3\": os.path.join(DATA_DIR, \"impl3\", \"par.csv\")\n",
    "}\n",
    "\n",
    "EXPECTED_COLS = [\n",
    "    \"implementation\",\"mode\",\"key\",\"p\",\"repetition\",\"time_seconds\",\n",
    "    \"iterations_done\",\"found\",\"finder_rank\",\"timestamp\",\"hostname\",\n",
    "    \"phrase\",\"text\",\"out_bin\"\n",
    "]\n",
    "\n",
    "ensureDir(LOGS_DIR)\n",
    "ensureDir(GRAPH_DIR)\n",
    "apply_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7730b",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13fd908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unifyCSV(files_dict, expected_cols=None):\n",
    "    \"\"\"\n",
    "    files_dict: dict mapping implementation -> csv_path\n",
    "    expected_cols: lista opcional de columnas que queremos garantizar en el DF final\n",
    "    \"\"\"\n",
    "    if expected_cols is None:\n",
    "        expected_cols = [\n",
    "            \"implementation\",\"mode\",\"key\",\"p\",\"repetition\",\"time_seconds\",\n",
    "            \"iterations_done\",\"found\",\"finder_rank\",\"timestamp\",\"hostname\",\n",
    "            \"phrase\",\"text\",\"out_bin\"\n",
    "        ]\n",
    "\n",
    "    dfs = []\n",
    "    for impl, file in files_dict.items():\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file,\n",
    "                parse_dates=[\"timestamp\"],\n",
    "                dtype={\n",
    "                    \"implementation\": str, \"mode\": str, \"key\": str,\n",
    "                    \"p\": \"Int64\", \"repetition\": \"Int64\",\n",
    "                    \"iterations_done\": \"Int64\", \"found\": \"Int64\",\n",
    "                    \"finder_rank\": \"Int64\", \"hostname\": str,\n",
    "                    \"phrase\": str, \"text\": str, \"out_bin\": str\n",
    "                },\n",
    "                keep_default_na=False  # evita convertir campos vacíos a NaN\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR leyendo {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Forzar implementation con la llave del dict (si quieres preservar, quita esta línea)\n",
    "        df[\"implementation\"] = impl\n",
    "\n",
    "        # Asegurar columnas esperadas (si faltan, se crean con valor vacío / nulo razonable)\n",
    "        for col in expected_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = \"\" if col in [\"phrase\", \"text\", \"out_bin\", \"mode\", \"hostname\"] else pd.NA\n",
    "\n",
    "        # Normalizar tipos/valores mínimos\n",
    "        df[\"text\"] = df[\"text\"].fillna(\"\")  # importante: text vacío cuando mode=decrypt\n",
    "        df[\"mode\"] = df[\"mode\"].fillna(\"decrypt\")\n",
    "        # asegurar numeric cast seguro (Int64 permite NA)\n",
    "        df[\"p\"] = pd.to_numeric(df[\"p\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df[\"repetition\"] = pd.to_numeric(df[\"repetition\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df[\"time_seconds\"] = pd.to_numeric(df[\"time_seconds\"], errors=\"coerce\").astype(float)\n",
    "        df[\"found\"] = pd.to_numeric(df[\"found\"], errors=\"coerce\").fillna(0).astype(\"Int64\")\n",
    "\n",
    "        dfs.append(df[expected_cols])\n",
    "\n",
    "    if not dfs:\n",
    "        return pd.DataFrame(columns=expected_cols)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "800a5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumeData(df, log_filename=\"resumen.log\", nombre=\"DataFrame\"):\n",
    "    log_path = os.path.join(LOGS_DIR, log_filename)\n",
    "    df2 = df.copy()\n",
    "\n",
    "    # Asegurar timestamp en datetime\n",
    "    if \"timestamp\" in df2.columns:\n",
    "        df2[\"timestamp\"] = pd.to_datetime(df2[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"===== Resumen: {nombre} =====\\n\")\n",
    "        f.write(f\"Tamaño: {df2.shape[0]} filas x {df2.shape[1]} columnas\\n\\n\")\n",
    "\n",
    "        f.write(\"Columnas y tipos de datos:\\n\")\n",
    "        f.write(df2.dtypes.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        f.write(\"Primeras 5 filas:\\n\")\n",
    "        f.write(df2.head().to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        f.write(\"Estadísticas básicas (numéricas):\\n\")\n",
    "        f.write(df2.describe().to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        # Conteos por implementation y por mode\n",
    "        f.write(\"Conteo por implementation:\\n\")\n",
    "        f.write(df2[\"implementation\"].value_counts().to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        if \"mode\" in df2.columns:\n",
    "            f.write(\"Conteo por mode:\\n\")\n",
    "            f.write(df2[\"mode\"].value_counts().to_string())\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "        # Filas con text vacío (útil para saber cuántas entradas paralelas)\n",
    "        if \"text\" in df2.columns:\n",
    "            empty_text = (df2[\"text\"].astype(str) == \"\").sum()\n",
    "            f.write(f\"Filas con 'text' vacío: {empty_text}\\n\\n\")\n",
    "\n",
    "        # Muestra algunas filas donde text está vacío y mode==decrypt (opcional)\n",
    "        if set([\"text\",\"mode\"]).issubset(df2.columns):\n",
    "            mask = (df2[\"text\"].astype(str) == \"\") & (df2[\"mode\"] == \"decrypt\")\n",
    "            f.write(\"Ejemplos (mode=decrypt y text vacío) - primeras 10:\\n\")\n",
    "            f.write(df2.loc[mask].head(10).to_string())\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Resumen guardado en: {log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9ee38",
   "metadata": {},
   "source": [
    "## Cálculos principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe85365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAverageTimeSec(dfSec, implName, key=None):\n",
    "    \"\"\"\n",
    "    Calcula el tiempo secuencial promedio para una implementación y llave opcional.\n",
    "    \"\"\"\n",
    "    df = dfSec[dfSec['implementation'] == implName]\n",
    "    if key is not None:\n",
    "        df = df[df['key'] == key]\n",
    "    return df['time_seconds'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0edf336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAverageTimePar(dfPar, implName, key=None, p=None):\n",
    "    \"\"\"\n",
    "    Calcula el tiempo paralelo promedio para una implementación, llave y número de procesos opcional.\n",
    "    \"\"\"\n",
    "    df = dfPar[dfPar['implementation'] == implName]\n",
    "    if key is not None:\n",
    "        df = df[df['key'] == key]\n",
    "    if p is not None:\n",
    "        df = df[df['p'] == p]\n",
    "    return df['time_seconds'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79fe0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSpeedup(tSec, tPar):\n",
    "    \"\"\"\n",
    "    Calcula el speedup: S = T_s / T_p\n",
    "    \"\"\"\n",
    "    return tSec / tPar if tPar > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43e6c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEfficiency(speedup, p):\n",
    "    \"\"\"\n",
    "    Calcula la eficiencia: E = S / p\n",
    "    \"\"\"\n",
    "    return speedup / p if p > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5887c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateFracSec(speedup, p):\n",
    "    \"\"\"\n",
    "    Estima la fracción secuencial usando la Ley de Amdahl: f ≈ (1/S - 1/p)/(1 - 1/p)\n",
    "    \"\"\"\n",
    "    if speedup <= 0 or p <= 1:\n",
    "        return np.nan\n",
    "    return (1/speedup - 1/p) / (1 - 1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0878c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePerformanceDF(dfSec, dfPar, logFilename=\"performance.log\"):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame con métricas principales (T_s, T_p, Speedup, Efficiency, FracSec)\n",
    "    para todas las implementaciones, llaves y valores de p disponibles.\n",
    "    Guarda un resumen en LOGS_DIR con formato tabular.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    implementations = dfSec['implementation'].unique()\n",
    "\n",
    "    for impl in implementations:\n",
    "        keys = dfSec[dfSec['implementation'] == impl]['key'].unique()\n",
    "        ps = dfPar[dfPar['implementation'] == impl]['p'].unique()\n",
    "\n",
    "        for key in keys:\n",
    "            tSec = computeAverageTimeSec(dfSec, impl, key)\n",
    "            for p_val in ps:\n",
    "                subsetPar = dfPar[(dfPar['implementation'] == impl) & \n",
    "                                  (dfPar['key'] == key) & \n",
    "                                  (dfPar['p'] == p_val)]\n",
    "                if subsetPar.empty:\n",
    "                    # Si no hay datos, saltar\n",
    "                    continue\n",
    "\n",
    "                tPar = computeAverageTimePar(dfPar, impl, key, p_val)\n",
    "                speedup = computeSpeedup(tSec, tPar)\n",
    "                efficiency = computeEfficiency(speedup, p_val)\n",
    "                fracSec = estimateFracSec(speedup, p_val)\n",
    "\n",
    "                results.append({\n",
    "                    \"implementation\": impl,\n",
    "                    \"key\": key,\n",
    "                    \"p\": p_val,\n",
    "                    \"T_s\": tSec,\n",
    "                    \"T_p\": tPar,\n",
    "                    \"Speedup\": speedup,\n",
    "                    \"Efficiency\": efficiency,\n",
    "                    \"FracSec\": fracSec\n",
    "                })\n",
    "\n",
    "    dfResults = pd.DataFrame(results)\n",
    "\n",
    "    logPath = os.path.join(\"./logs\", logFilename)\n",
    "    with open(logPath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"===== Resumen de rendimiento =====\\n\")\n",
    "        f.write(f\"Tamaño: {dfResults.shape[0]} filas x {dfResults.shape[1]} columnas\\n\\n\")\n",
    "        f.write(tabulate(dfResults, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "\n",
    "    print(f\"Resumen guardado en: {logPath}\")\n",
    "    return dfResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3b93f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePerformanceDF_with_baseline(dfSec, dfPar, impl_baseline=\"impl1\", logFilename=\"perf_summary.log\"):\n",
    "    results = []\n",
    "\n",
    "    # Keys disponibles para el baseline\n",
    "    keys = (dfSec.loc[dfSec['implementation'] == impl_baseline, 'key']\n",
    "                  .astype(str).unique())\n",
    "\n",
    "    # Precalcular T_s por key (baseline)\n",
    "    ts_by_key = {\n",
    "        k: dfSec[(dfSec['implementation'] == impl_baseline) & (dfSec['key'].astype(str) == str(k))]\n",
    "               ['time_seconds'].mean()\n",
    "        for k in keys\n",
    "    }\n",
    "\n",
    "    # Implementaciones paralelas a comparar (todas las presentes)\n",
    "    impls_par = dfPar['implementation'].unique()\n",
    "\n",
    "    for impl in impls_par:\n",
    "        df_impl = dfPar[dfPar['implementation'] == impl]\n",
    "        ps = pd.Series(df_impl['p'].unique()).dropna().tolist()\n",
    "        for k in keys:\n",
    "            # subconjunto paralelo por key\n",
    "            g = df_impl[df_impl['key'].astype(str) == str(k)]\n",
    "            if g.empty:\n",
    "                continue\n",
    "            for p_val in sorted(pd.Series(g['p'].unique()).dropna()):\n",
    "                tPar = g[g['p'] == p_val]['time_seconds'].mean()\n",
    "                tSec = ts_by_key.get(k, np.nan)\n",
    "                if pd.isna(tSec) or pd.isna(tPar):\n",
    "                    continue\n",
    "                S = computeSpeedup(tSec, tPar)\n",
    "                E = computeEfficiency(S, p_val)\n",
    "                f = estimateFracSec(S, p_val)\n",
    "                results.append({\n",
    "                    \"implementation\": impl,\n",
    "                    \"key\": k,\n",
    "                    \"p\": p_val,\n",
    "                    \"T_s\": tSec,\n",
    "                    \"T_p\": tPar,\n",
    "                    \"Speedup\": S,\n",
    "                    \"Efficiency\": E,\n",
    "                    \"FracSec\": f,\n",
    "                    \"baseline_impl\": impl_baseline\n",
    "                })\n",
    "\n",
    "    dfResults = pd.DataFrame(results)\n",
    "\n",
    "    logPath = os.path.join(LOGS_DIR, logFilename)\n",
    "    with open(logPath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"===== Resumen de rendimiento (baseline={impl_baseline}) =====\\n\")\n",
    "        f.write(f\"Tamaño: {dfResults.shape[0]} filas x {dfResults.shape[1]} columnas\\n\\n\")\n",
    "        f.write(tabulate(dfResults, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "    print(f\"Resumen guardado en: {logPath}\")\n",
    "    return dfResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfd445",
   "metadata": {},
   "source": [
    "## Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd58b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotExecutionTimeVsP(dfResults, savePath=None):\n",
    "    \"\"\"\n",
    "    Gráfico de T_p vs número de procesos p para cada implementación.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for (impl, key), g in (dfResults\n",
    "                           .sort_values(\"p\")\n",
    "                           .groupby([\"implementation\",\"key\"], sort=False)):\n",
    "        ax.plot(g[\"p\"], g[\"T_p\"], marker=\"o\", linewidth=2,\n",
    "                label=f\"{impl} · key={key}\")\n",
    "\n",
    "    ax.set_xlabel('Número de procesos (p)')\n",
    "    ax.set_ylabel('Tiempo paralelo T_p (s)')\n",
    "    ax.set_title('Tiempo de ejecución vs número de procesos')\n",
    "    ax.set_xticks(sorted(dfResults[\"p\"].unique()))\n",
    "    ax.margins(x=0.02, y=0.05)\n",
    "    # Leyenda afuera para no tapar\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1.0), title=\"Serie\")\n",
    "    fig.tight_layout()\n",
    "    if savePath: fig.savefig(savePath, bbox_inches='tight', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26f48c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSpeedupVsP(dfResults, savePath=None):\n",
    "    \"\"\"\n",
    "    Gráfico de Speedup vs número de procesos p, con línea ideal S=p.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ps_sorted = sorted(dfResults[\"p\"].unique())\n",
    "    ax.plot(ps_sorted, ps_sorted, linestyle='--', linewidth=1.5, label='Ideal S=p', color='0.2')\n",
    "\n",
    "    for (impl, key), g in (dfResults\n",
    "                           .sort_values(\"p\")\n",
    "                           .groupby([\"implementation\",\"key\"], sort=False)):\n",
    "        ax.plot(g[\"p\"], g[\"Speedup\"], marker=\"o\", linewidth=2,\n",
    "                label=f\"{impl} · key={key}\")\n",
    "\n",
    "    ax.set_xlabel('Número de procesos (p)')\n",
    "    ax.set_ylabel('Speedup S')\n",
    "    ax.set_title('Speedup vs número de procesos')\n",
    "    ax.set_xticks(ps_sorted)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1.0), title=\"Serie\")\n",
    "    fig.tight_layout()\n",
    "    if savePath: fig.savefig(savePath, bbox_inches='tight', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47d7a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotEfficiencyVsP(dfResults, savePath=None):\n",
    "    \"\"\"\n",
    "    Gráfico de eficiencia vs número de procesos p para cada implementación.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for (impl, key), g in (dfResults\n",
    "                           .sort_values(\"p\")\n",
    "                           .groupby([\"implementation\",\"key\"], sort=False)):\n",
    "        ax.plot(g[\"p\"], g[\"Efficiency\"], marker=\"o\", linewidth=2,\n",
    "                label=f\"{impl} · key={key}\")\n",
    "\n",
    "    ax.axhline(1.0, linestyle='--', linewidth=1, color='0.5')\n",
    "    ax.axhline(0.5, linestyle=':', linewidth=1, color='0.5')\n",
    "\n",
    "    ax.set_xlabel('Número de procesos (p)')\n",
    "    ax.set_ylabel('Eficiencia E')\n",
    "    ax.set_title('Eficiencia vs número de procesos')\n",
    "    ax.set_xticks(sorted(dfResults[\"p\"].unique()))\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1.0), title=\"Serie\")\n",
    "    fig.tight_layout()\n",
    "    if savePath: fig.savefig(savePath, bbox_inches='tight', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bdb84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBoxplotTimeByKey(dfPar, savePath=None):\n",
    "    \"\"\"\n",
    "    Boxplot de tiempos paralelos por key y por implementación.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    sns.boxplot(\n",
    "        x='key', y='time_seconds', hue='implementation', data=dfPar,\n",
    "        linewidth=1.2, fliersize=2, dodge=True, ax=ax, palette='Set2'\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('Key')\n",
    "    ax.set_ylabel('Tiempo paralelo T_p (s)')\n",
    "    ax.set_title('Distribución de tiempo paralelo por key')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1.0), title=\"impl\")\n",
    "    fig.tight_layout()\n",
    "    if savePath: fig.savefig(savePath, bbox_inches='tight', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58dc1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotComparisonSequentialVsParallel(dfResults, savePath=None):\n",
    "    \"\"\"\n",
    "    Barras agrupadas de T_s vs T_p promedio por implementación.\n",
    "    \"\"\"\n",
    "    dfAvg = (dfResults.groupby('implementation')[['T_s','T_p']]\n",
    "             .mean().reset_index())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 0.38\n",
    "    x = range(len(dfAvg))\n",
    "    ax.bar([i - width/2 for i in x], dfAvg['T_s'], width, label='T_s')\n",
    "    ax.bar([i + width/2 for i in x], dfAvg['T_p'], width, label='T_p')\n",
    "    ax.set_xticks(list(x))\n",
    "    ax.set_xticklabels(dfAvg['implementation'])\n",
    "    ax.set_ylabel('Tiempo promedio (s)')\n",
    "    ax.set_title('Comparación secuencial vs paralelo')\n",
    "    ax.legend(title=None)\n",
    "    for i, v in enumerate(dfAvg['T_s']):\n",
    "        ax.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    for i, v in enumerate(dfAvg['T_p']):\n",
    "        ax.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    fig.tight_layout()\n",
    "    if savePath: fig.savefig(savePath, bbox_inches='tight', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4af125",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c45e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sec = unifyCSV(seq_files)\n",
    "df_par = unifyCSV(par_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sec = df_sec[df_sec['mode'] == 'decrypt']\n",
    "df_par = df_par[(df_par['mode'] == 'decrypt') & (df_par['p'] > 0)]\n",
    "df_par = df_par[df_par['found'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HOST != \"all\":\n",
    "    df_sec = df_sec[df_sec['hostname'] == HOST]\n",
    "    df_par = df_par[df_par['hostname'] == HOST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumeData(df=df_sec, log_filename=f\"{HOST}_secuencial_resumen.log\", nombre=f\"Secuencial ({HOST})\")\n",
    "resumeData(df=df_par, log_filename=f\"{HOST}_paralelo_resumen.log\",  nombre=f\"Paralelo ({HOST})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cabea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfDF = generatePerformanceDF(df_sec, df_par, logFilename=f\"{HOST}_perf_summary_A.log\")\n",
    "plotExecutionTimeVsP(perfDF, f\"{GRAPH_DIR}/{HOST}_ea_exec_time_vs_p.png\")\n",
    "plotSpeedupVsP(perfDF, f\"{GRAPH_DIR}/{HOST}_ea_speedup_vs_p.png\")\n",
    "plotEfficiencyVsP(perfDF, f\"{GRAPH_DIR}/{HOST}_ea_efficiency_vs_p.png\")\n",
    "plotBoxplotTimeByKey(df_par, f\"{GRAPH_DIR}/{HOST}_ea_boxplot_time_by_key.png\")\n",
    "plotComparisonSequentialVsParallel(perfDF, f\"{GRAPH_DIR}/{HOST}_ea_seq_vs_par.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53081819",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfDF2 = generatePerformanceDF_with_baseline(df_sec, df_par, impl_baseline=\"impl1\", logFilename=f\"{HOST}_perf_summary_B.log\")\n",
    "plotExecutionTimeVsP(perfDF2, f\"{GRAPH_DIR}/{HOST}_eb_exec_time_vs_p.png\")\n",
    "plotSpeedupVsP(perfDF2, f\"{GRAPH_DIR}/{HOST}_eb_speedup_vs_p.png\")\n",
    "plotEfficiencyVsP(perfDF2, f\"{GRAPH_DIR}/{HOST}_eb_efficiency_vs_p.png\")\n",
    "plotBoxplotTimeByKey(df_par, f\"{GRAPH_DIR}/{HOST}_eb_boxplot_time_by_key.png\")\n",
    "plotComparisonSequentialVsParallel(perfDF2, f\"{GRAPH_DIR}/{HOST}_eb_seq_vs_par.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
